{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aee0df3b-8852-4bfc-976b-bc7cb348359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "with open(\"nebius_api_key\", \"r\") as file:\n",
    "    nebius_api_key = file.read().strip()\n",
    "\n",
    "os.environ[\"NEBIUS_API_KEY\"] = nebius_api_key\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# Nebius uses the same OpenAI() class, but with additional details\n",
    "nebius_client = OpenAI(\n",
    "    base_url=\"https://api.studio.nebius.ai/v1/\",\n",
    "    api_key=os.environ.get(\"NEBIUS_API_KEY\"),\n",
    ")\n",
    "\n",
    "llm_model = \"meta-llama/Meta-Llama-3.1-405B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a1e2699-4df0-40b9-a827-6bab94a93215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettify_string(text, max_line_length=80):\n",
    "    \"\"\"Prints a string with line breaks at spaces to prevent horizontal scrolling.\n",
    "\n",
    "    Args:\n",
    "        text: The string to print.\n",
    "        max_line_length: The maximum length of each line.\n",
    "    \"\"\"\n",
    "\n",
    "    output_lines = []\n",
    "    lines = text.split(\"\\n\") #Split the chunk of text retrieved from LLM into lines\n",
    "    for line in lines:       #Loop all the lines\n",
    "        current_line = \"\"\n",
    "        words = line.split() #Split the lines into words separate by whitespace\n",
    "        for word in words:\n",
    "            if len(current_line) + len(word) + 1 <= max_line_length:\n",
    "                current_line += word + \" \"\n",
    "            else:\n",
    "                output_lines.append(current_line.strip())\n",
    "                current_line = word + \" \"\n",
    "        output_lines.append(current_line.strip())  # Append the last line\n",
    "    return \"\\n\".join(output_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8394beba-3156-4efe-ab5e-81798fa5c5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_with_llm(prompt: str,\n",
    "                    system_prompt,\n",
    "                    max_tokens=512,\n",
    "                    client=nebius_client,\n",
    "                    model=llm_model,\n",
    "                    prettify=True,\n",
    "                    temperature=0.7) -> str:\n",
    "\n",
    "    messages = []\n",
    "\n",
    "    if system_prompt:\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            }\n",
    "        )\n",
    "\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    )\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    if prettify:\n",
    "        return prettify_string(completion.choices[0].message.content)\n",
    "    else:\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d27a53d2-0ce6-47c7-baf8-d09f8e930fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_in_stages(input: str, language: str) -> str:\n",
    "    print(\"=== LITERAL TRANSLATION ===\")\n",
    "    literal_translation = answer_with_llm(\n",
    "        f\"\"\"Translate the following children's rhyme into {language}, \n",
    "word for word, focusing on preserving the original meaning. Do not try to make it rhyme:\\n\\n{input}\"\"\",\n",
    "        \"You are a professional translator.\"\n",
    "    )\n",
    "    print(\"A: \"+literal_translation)\n",
    "\n",
    "    print(\"\\n=== RHYMED TRANSLATION ===\")\n",
    "    rhymed_translation = answer_with_llm(\n",
    "        f\"\"\"Take the following literal translation of a rhyme in {language} and rewrite it so it has rhyme and rhythm, \n",
    "even if you must lose some literal meaning. Return only the revised poem:\\n\\n{literal_translation}\"\"\",\n",
    "        \"You are a skilled poet.\"\n",
    "    )\n",
    "    print(\"B: \"+rhymed_translation)\n",
    "\n",
    "    print(\"\\n=== FINAL EDITED VERSION ===\")\n",
    "    final_version = answer_with_llm(\n",
    "        f\"\"\"Here is the original English rhyme and a translated version \n",
    "in {language}:\\n\\nOriginal:\\n{input}\\n\\nTranslation:\\n{rhymed_translation}\\n\\nEdit the translation for clarity, \n",
    "beauty, rhyme, and flow, while keeping as much of the original meaning as possible. Return only the final poem.\"\"\",\n",
    "        \"You are an experienced editor of poetry.\"\n",
    "    )\n",
    "    print(\"C: \"+final_version)\n",
    "    return final_version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e856b38-5f10-400d-8a37-af3922958dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LITERAL TRANSLATION ===\n",
      "A: Here's a word-for-word translation of the children's rhyme into French,\n",
      "preserving the original meaning:\n",
      "\n",
      "Humpty Dumpty était assis sur un mur,\n",
      "Humpty Dumpty a eu une grande chute.\n",
      "Tous les chevaux du roi et tous les hommes du roi\n",
      "N'ont pas pu remettre Humpty ensemble à nouveau.\n",
      "\n",
      "Note that I've kept the name 'Humpty Dumpty' as it is since it's a proper noun\n",
      "and a well-known character, even in French-speaking countries.\n",
      "\n",
      "=== RHYMED TRANSLATION ===\n",
      "B: Humpty Dumpty sat on a wall so high,\n",
      "He tumbled down with a sorrowful sigh.\n",
      "The king's horses and men all came by,\n",
      "But none could mend poor Humpty, and he wondered why.\n",
      "\n",
      "=== FINAL EDITED VERSION ===\n",
      "C: Humpty Dumpty s'assit sur un mur si haut,\n",
      "Il tomba bas avec un triste cri sauvage.\n",
      "Les chevaux et les hommes du roi vinrent tous,\n",
      "Mais aucun ne put réparer l'infortuné, pauvre Humpty, jamais.\n",
      "\n",
      "=== RESULT ===\n",
      "D: Humpty Dumpty s'assit sur un mur si haut,\n",
      "Il tomba bas avec un triste cri sauvage.\n",
      "Les chevaux et les hommes du roi vinrent tous,\n",
      "Mais aucun ne put réparer l'infortuné, pauvre Humpty, jamais.\n"
     ]
    }
   ],
   "source": [
    "language = \"French\"\n",
    "poem = \"\"\"Humpty Dumpty sat on a wall,\n",
    "Humpty Dumpty had a great fall.\n",
    "All the king's horses and all the king's men\n",
    "Couldn't put Humpty together again.\"\"\"\n",
    "\n",
    "result = translate_in_stages(poem, language)\n",
    "print(\"\\n=== RESULT ===\")\n",
    "print(\"D: \"+result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69178df-1b8b-4e58-9941-9c43fea6630f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
